

・**TimeCMA** TimeCMA: Towards LLM-Empowered Multivariate Time Series Forecasting via Cross-Modality Alignment [(AAAI 2025)](https://arxiv.org/abs/2406.01638) [Code](https://github.com/ChenxiLiu-HNU/TimeCMA.git)

・**AutoTimes** AutoTimes: Autoregressive Time Series Forecasters via Large Language Models [(NeurIPS 2024)](https://arxiv.org/abs/2402.02370) [Code](https://github.com/thuml/AutoTimes.git)

・**Time-LLM** Time-LLM: Time Series Forecasting by Reprogramming Large Language Models [(ICLR 2024)](https://arxiv.org/abs/2310.01728) [Code](https://github.com/KimMeen/Time-LLM.git)

・**OFA** One Fits All:Power General Time Series Analysis by Pretrained LM [(NeurIPS 2023)](https://arxiv.org/abs/2302.11939) [Code](https://github.com/DAMO-DI-ML/NeurIPS2023-One-Fits-All.git)

・**LLMTime** Large Language Models Are Zero-Shot Time Series Forecasters [(NeurIPS 2023)](https://arxiv.org/abs/2310.07820) [Code](https://github.com/ngruver/llmtime.git)



